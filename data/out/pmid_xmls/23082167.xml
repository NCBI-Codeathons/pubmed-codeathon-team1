<!DOCTYPE PubmedArticleSet PUBLIC "-//NLM//DTD PubMedArticle, 1st January 2019//EN" "https://dtd.nlm.nih.gov/ncbi/pubmed/out/pubmed_190101.dtd">
<PubmedArticleSet>
  <PubmedArticle>
    <MedlineCitation Status="MEDLINE" Owner="NLM">
      <PMID Version="1">23082167</PMID>
      <DateCompleted>
        <Year>2013</Year>
        <Month>04</Month>
        <Day>09</Day>
      </DateCompleted>
      <DateRevised>
        <Year>2021</Year>
        <Month>10</Month>
        <Day>21</Day>
      </DateRevised>
      <Article PubModel="Print-Electronic">
        <Journal>
          <ISSN IssnType="Electronic">1932-6203</ISSN>
          <JournalIssue CitedMedium="Internet">
            <Volume>7</Volume>
            <Issue>10</Issue>
            <PubDate>
              <Year>2012</Year>
            </PubDate>
          </JournalIssue>
          <Title>PloS one</Title>
          <ISOAbbreviation>PLoS One</ISOAbbreviation>
        </Journal>
        <ArticleTitle>Prosody discrimination by songbirds (Padda oryzivora).</ArticleTitle>
        <Pagination>
          <StartPage>e47446</StartPage>
          <MedlinePgn>e47446</MedlinePgn>
        </Pagination>
        <ELocationID EIdType="pii" ValidYN="Y">e47446</ELocationID>
        <ELocationID EIdType="doi" ValidYN="Y">10.1371/journal.pone.0047446</ELocationID>
        <Abstract>
          <AbstractText>In human verbal communication, not only lexical information, but also paralinguistic information plays an important role in transmitting the speakers' mental state. Paralinguistic information is conveyed mainly through acoustic features like pitch, rhythm, tempo and so on. These acoustic features are generally known as prosody. It is known that some species of birds can discriminate certain aspects of human speech. However, there have not been any studies on the discrimination of prosody in human language which convey different paralinguistic meanings by birds. In the present study, we have shown that the Java sparrow (Padda oryzivora) can discriminate different prosodic patterns of Japanese sentences. These birds could generalize prosodic discrimination to novel sentences, but could not generalize sentence discrimination to those with novel prosody. Moreover, unlike Japanese speakers, Java sparrows used the first part of the utterance as the discrimination cue.</AbstractText>
        </Abstract>
        <AuthorList CompleteYN="Y">
          <Author ValidYN="Y">
            <LastName>Naoi</LastName>
            <ForeName>Nozomi</ForeName>
            <Initials>N</Initials>
            <AffiliationInfo>
              <Affiliation>Department of Psychology, Keio University, Tokyo, Japan. nnaoi@educ.kyoto-u.ac.jp</Affiliation>
            </AffiliationInfo>
          </Author>
          <Author ValidYN="Y">
            <LastName>Watanabe</LastName>
            <ForeName>Shigeru</ForeName>
            <Initials>S</Initials>
          </Author>
          <Author ValidYN="Y">
            <LastName>Maekawa</LastName>
            <ForeName>Kikuo</ForeName>
            <Initials>K</Initials>
          </Author>
          <Author ValidYN="Y">
            <LastName>Hibiya</LastName>
            <ForeName>Junko</ForeName>
            <Initials>J</Initials>
          </Author>
        </AuthorList>
        <Language>eng</Language>
        <PublicationTypeList>
          <PublicationType UI="D016428">Journal Article</PublicationType>
          <PublicationType UI="D013485">Research Support, Non-U.S. Gov't</PublicationType>
        </PublicationTypeList>
        <ArticleDate DateType="Electronic">
          <Year>2012</Year>
          <Month>10</Month>
          <Day>17</Day>
        </ArticleDate>
      </Article>
      <MedlineJournalInfo>
        <MedlineTA>PLoS One</MedlineTA>
        <NlmUniqueID>101285081</NlmUniqueID>
        <ISSNLinking>1932-6203</ISSNLinking>
      </MedlineJournalInfo>
      <CitationSubset>IM</CitationSubset>
      <MeshHeadingList>
        <MeshHeading>
          <DescriptorName UI="D000161" MajorTopicYN="N">Acoustic Stimulation</DescriptorName>
        </MeshHeading>
        <MeshHeading>
          <DescriptorName UI="D000818" MajorTopicYN="N">Animals</DescriptorName>
        </MeshHeading>
        <MeshHeading>
          <DescriptorName UI="D004192" MajorTopicYN="N">Discrimination, Psychological</DescriptorName>
          <QualifierName UI="Q000502" MajorTopicYN="Y">physiology</QualifierName>
        </MeshHeading>
        <MeshHeading>
          <DescriptorName UI="D006801" MajorTopicYN="N">Humans</DescriptorName>
        </MeshHeading>
        <MeshHeading>
          <DescriptorName UI="D008297" MajorTopicYN="N">Male</DescriptorName>
        </MeshHeading>
        <MeshHeading>
          <DescriptorName UI="D020308" MajorTopicYN="N">Songbirds</DescriptorName>
          <QualifierName UI="Q000502" MajorTopicYN="Y">physiology</QualifierName>
        </MeshHeading>
        <MeshHeading>
          <DescriptorName UI="D013061" MajorTopicYN="Y">Speech Acoustics</DescriptorName>
        </MeshHeading>
      </MeshHeadingList>
      <CoiStatement><b>Competing Interests: </b>The authors have declared that no competing interests exist.</CoiStatement>
    </MedlineCitation>
    <PubmedData>
      <History>
        <PubMedPubDate PubStatus="received">
          <Year>2011</Year>
          <Month>11</Month>
          <Day>30</Day>
        </PubMedPubDate>
        <PubMedPubDate PubStatus="accepted">
          <Year>2012</Year>
          <Month>9</Month>
          <Day>17</Day>
        </PubMedPubDate>
        <PubMedPubDate PubStatus="entrez">
          <Year>2012</Year>
          <Month>10</Month>
          <Day>20</Day>
          <Hour>6</Hour>
          <Minute>0</Minute>
        </PubMedPubDate>
        <PubMedPubDate PubStatus="pubmed">
          <Year>2012</Year>
          <Month>10</Month>
          <Day>20</Day>
          <Hour>6</Hour>
          <Minute>0</Minute>
        </PubMedPubDate>
        <PubMedPubDate PubStatus="medline">
          <Year>2013</Year>
          <Month>4</Month>
          <Day>10</Day>
          <Hour>6</Hour>
          <Minute>0</Minute>
        </PubMedPubDate>
      </History>
      <PublicationStatus>ppublish</PublicationStatus>
      <ArticleIdList>
        <ArticleId IdType="pubmed">23082167</ArticleId>
        <ArticleId IdType="pmc">PMC3474804</ArticleId>
        <ArticleId IdType="doi">10.1371/journal.pone.0047446</ArticleId>
        <ArticleId IdType="pii">PONE-D-11-24212</ArticleId>
      </ArticleIdList>
      <ReferenceList>
        <Reference>
          <Citation>
Ackerman BP (1983) Form and function in children’s understanding of ironic utterances. J Exp Child Psychol
35: 487–508.</Citation>
        </Reference>
        <Reference>
          <Citation>
Ladd DR, Silverman KEA, Tolkmitt F, Bergman G, Scherer KR (1985) Evidence for the independent function of contour type, voice quality, and F0 range in signaling speaker affect. J Acoust Soc Am
78: 435–444.</Citation>
        </Reference>
        <Reference>
          <Citation>
Lieberman P, Michaels SB (1962) Some aspects of fundamental frequency and envelope amplitude as related to the emotional content of speech. J Acoust Soc Am
34: 922–927.</Citation>
        </Reference>
        <Reference>
          <Citation>
Mehrabian A, Weiner M (1967) Decoding of inconsistent communications. J Pers Soc Psychol
6: 109–114.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">6032751</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Scherer KR, Banse R, Wallbott HG, Goldbeck T (1991) Vocal cues in emotion encoding and decoding. Motiv Emot
15: 123–148.</Citation>
        </Reference>
        <Reference>
          <Citation>
Scherer KR, Oshinsky JS (1977) Cue utilization in emotion attribution from auditory stimuli. Motiv Emot
1: 331–346.</Citation>
        </Reference>
        <Reference>
          <Citation>
Fernald A, Mazzie C (1991) Prosody and focus in speech to infants and adults. Dev Psychol
27: 209–221.</Citation>
        </Reference>
        <Reference>
          <Citation>
Hirsh-Pasek K, Kemler-Nelson DG, Jusczyk PW, Cassidy KW, Druss B, et al. (1987) Clauses are perceptual units for young infants. Cognition
26: 269–286.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">3677573</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Jusczyk PW, Hirsh-Pasek K, Kemler-Nelson DG, Kennedy L, Woodward A, et al. (1992) Perception of acoustic correlates of major phrasal units by young infants. Cogn Psychol
24: 252–293.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">1582173</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Morgan JL (1994) Converging measures of speech segmentation in preverbal infants. Infant Behav Dev
17: 389–403.</Citation>
        </Reference>
        <Reference>
          <Citation>Peters A (1985) Language segmentation: Operating principles for the perception and analysis of language. In: Slobin DI, editor. The crosslinguistic study of language acquisition, Vol.2: Theoretical issues. New Jersey: Lawrence Erlbaum. 1029–1067.</Citation>
        </Reference>
        <Reference>
          <Citation>
Gosy M, Terken J (1994) Question marking in Hungarian: Timing and Height of pitch peaks. J Phon
22: 269–281.</Citation>
        </Reference>
        <Reference>
          <Citation>
Kawakami S (1963) Bunmatsu nadono jooshoochooni tsuite [On final rise]. Kokugokenkyuu
16: 25–46 (in Japanese)..</Citation>
        </Reference>
        <Reference>
          <Citation>Ladd DR (1996) Intonational phonology. Cambridge: Cambridge University Press. 352p.</Citation>
        </Reference>
        <Reference>
          <Citation>
Thorsen N (1980) A study of the perception of sentence intonation evidence from Danish. J Acoust Soc Am
67: 1015–1030.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">7358909</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Makarova V (2001) Perceptual correlates of sentence-type intonation in Russian and Japanese. J Phon
29: 137–154.</Citation>
        </Reference>
        <Reference>
          <Citation>
Fernald A (1993) Approval and disapproval: infant responsiveness to vocal affect in familiar and unfamiliar languages. Child Dev
64: 657–674.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">8339687</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Jusczyk PW (1999) How infants begin to extract words from speech. Trends Cogn Sci
3: 323–328.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">10461194</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Cutler A, Mehler J (1993) The periodicity bias. J Phon
21: 103–108.</Citation>
        </Reference>
        <Reference>
          <Citation>
Jusczyk PW (1993) From general to language-specific capacities: The WRAPSA model of how speech perception develops. J Phon
21: 3–28.</Citation>
        </Reference>
        <Reference>
          <Citation>
Morgan J, Newport E (1981) The role of constituent structure in the induction of an artificial language. J Verbal Learn Verbal Behav
20: 67–85.</Citation>
        </Reference>
        <Reference>
          <Citation>
Nazzi T, Ramus F (2003) Perception and acquisition of linguistic rhythm by infants. Speech Commun
41: 233–243.</Citation>
        </Reference>
        <Reference>
          <Citation>
Soderstrom M, Seidl A, Kemler-Nelson DG, Jusczyk PW (2003) The prosodic bootstrapping of phrases: Evidence from prelinguistic infants. J Mem Lang
49: 249–267.</Citation>
        </Reference>
        <Reference>
          <Citation>
Grossmann T, Striano T, Friederici AD (2005) Infants’ electric brain responses to emotional prosody. Neuroreport
16: 1825–1828.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">16237335</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Fernald A (1993) Approval and disapproval: infant responsiveness to vocal affect in familiar and unfamiliar languages. Child Dev
64: 657–674.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">8339687</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Kojima S, Kiritani S (1989) Vocal-auditory functions in the chimpanzee: Vowel perception. Int J Primatol
10: 199–213.</Citation>
        </Reference>
        <Reference>
          <Citation>
Morse PA, Snowdon CT (1975) An investigation of categorical speech discrimination by rhesus monkeys. Percept Psychophys
17: 9–16.</Citation>
        </Reference>
        <Reference>
          <Citation>
Ramus F, Hauser MD, Miller C, Morris D, Mehler J (2000) Language Discrimination by Human Newborns and by Cotton-Top Tamarin Monkeys. Science
288: 349–351.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">10764650</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Kuhl PK, Miller JD (1978) Speech perception by the chinchilla: Identification functions for synthetic VOT stimuli. J Acoust Soc Am
63: 905–917.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">670558</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Toro JM, Trobalon JB, Sebastián-Gallés N (2003) The use of prosodic cues in language discrimination tasks by rats. Anim Cogn
6: 131–136.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">12728358</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Toro JM, Trobalon JB, Sebastián-Gallés N (2005) Effects of backward speech and speaker variability in language discrimination by rats. J Exp Psychol Anim Behav Process
31: 95–100.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">15656730</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>Carew T (2000) Behavioral neurobiology: The cellular organization of natural behavior. Massachusetts: Sinauer Associates. 435p.</Citation>
        </Reference>
        <Reference>
          <Citation>
Doupe AJ, Kuhl PK (1999) Birdsong and human speech: Common Themes and Mechanisms. Annu Rev Neurosci
22: 567–631.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">10202549</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Dooling RJ, Best CT, Brown SD (1995) Discrimination of synthetic full-formant and sinewave/ra-la/continua by budgerigars (Melopsittacus undulates) and zebra finches (Taenipygia guttata). J Acoust Soc Am
97: 1839–1846.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">7699165</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Weisman R, Njegovan M, Sturdy C (1998) Frequency-range discriminations: Special and general abilities in zebra finches (Taeniopygia guttata) and humans (Homo sapiens). J Comp Psychol
112: 244–258.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">9770314</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Watanabe S, Sato K (1999) Discriminative stimulus properties of music in Java sparrows. Behav Processes
47: 53–57.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">24896693</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Watanabe S, Uozumi M, Tanaka N (2005) Discrimination of consonance and dissonance in Java sparrows. Behav Processes
70: 203–208.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">16043306</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Watanabe S, Yamamoto E, Uozumi M (2006) Language discrimination by Java sparrows. Behav Processes
73: 114–116.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">16524672</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Dent ML, Brittan-Powell EF, Dooling RJ, Pierce A (1997) Discrimination of synthetic/ba/−/wa/by budgerigars (Melopsittacus undulatus). J Acoust Soc Am
102: 1891–1897.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">9301066</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Dent ML, Dooling RJ, Pierce AS (2000) Frequency discrimination in budgerigars (Melopsittacus undulatus): Effects of tone duration and tonal context. J Acoust Soc Am
107: 2657–2664.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">10830387</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Dooling RJ, Okanoya K, Brown SD (1989) Speech perception by budgerigars (Melopsittacus undulatus): The voiced-voiceless distinction. Percept Psychophys
46: 65–71.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">2755763</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Kluender KR, Diehl RL, Killeen PR (1987) Japanese quail can learn phonetic categories. Science
237: 1195–1197.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">3629235</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Lotto AJ, Kluender KR, Holt LL (1997) Perceptual compensation for coarticulation by Japanese quail (Coturnix coturnix japonica). J Acoust Soc Am
102: 1134–1140.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">9265760</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Kluender KR, Lotto AJ, Holt LL, Bloedel SL (1998) Role of experience for language-specific functional mappings of vowel sounds. J Acoust Soc Am
104: 3568–3582.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">9857515</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
MacDougall-Shackleton SA, Hulse SH (1996) Concurrent absolute and relative pitch processing by European starlings (Sturnus vulgaris). J Comp Psychol
110: 139–146.</Citation>
        </Reference>
        <Reference>
          <Citation>
Pisacreta R, Gough D, Redwood E, Goodfellow L (1986) Auditory word discriminations in the pigeon. J Exp Anal Behav
45: 269–282.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pmc">PMC1348238</ArticleId>
            <ArticleId IdType="pubmed">3711775</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Tincoff R, Hauser M, Tsao F, Spaepen G, Ramus F, et al. (2005) The role of speech rhythm in language discrimination: further tests with a non-human primate. Dev Sci
8: 26–35.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">15647064</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Toro JM, Sinnett S, Soto-Faraco S (2005) Speech segmentation by statistical learning depends on attention. Cognition
97: B25–34.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">16226557</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Banse R, Scherer KR (1996) Acoustic profiles in vocal emotion expression. J Pers Soc Psychol
70: 614–636.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">8851745</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Thompson WF, Balkwill L-L (2006) Decoding speech prosody in five languages. Semiotica
158: 407–424.</Citation>
        </Reference>
        <Reference>
          <Citation>
Lee TT, Charrier I, Bloomfield LL, Weisman RG, Sturdy CB (2006) Frequency-range discriminations and absolute pitch in black-capped chickadees (Poecile atricapillus), mountain chickadees (Poecile gambeli), and zebra finches (Taeniopygia guttata). J Comp Psychol
120: 217–228.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">16893259</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Njegovan M, Ito S, Mewhort D, Weisman R (1995) Classification of frequencies into ranges by songbirds and humans. J Exp Psychol Anim Behav Process
21: 33–42.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">7844505</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Weisman RG, Hoeschele M, Bloomfield LL, Mewhort D, Sturdy CB (2010) Using network models of absolute pitch to compare frequency-range discriminations across avian species. Behav Processes
84: 421–427.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">20097276</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Sinnott JM (1987) Modes of perceiving and processing information in birdsong (Agelaius phoeniceus, Molothrus ater, and Homo sapiens). J Comp Psychol
101: 355–366.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">3691059</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Maekawa K (1998) Phonetic and phonological characteristics of paralinguistic information in spoken Japanese. Proceeding of the 5th International Conference on Spoken Language Processing
2: 635–638.</Citation>
        </Reference>
        <Reference>
          <Citation>
Vicario DS (1994) Motor mechanisms relevant to auditory-vocal interactions in songbirds. Brain Behav Evol
44: 265–278.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">7842285</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Margoliash D, Fortune ES, Sutter ML, Yu AC, Wren-Hardin BD, et al. (1994) Distributed representation in the song system of oscines: evolutionary implications and functional consequences. Brain Behav Evol
44: 247–264.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">7842284</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Ball GF (1994) Neurochemical specializations associated with vocal learning and production in songbirds and budgerigars. Brain Behav Evol
44: 234–246.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">7842283</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Nachtigall PE, Pawloski JL, Au WW (2003) Temporary threshold shifts and recovery following noise exposure in the Atlantic bottlenosed dolphin (Tursiops truncatus). J Acoust Soc Am
113: 3425–3429.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">12822812</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Poole JH, Tyack PL, Stoeger-Horwath AS, Watwood S (2005) Animal behaviour: elephants are capable of vocal learning. Nature
434: 455–456.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">15791244</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>
Metzner W (1996) Anatomical basis for audio-vocal integration in echolocating horseshoe bats. J Comp Neurol
368: 252–269.</Citation>
          <ArticleIdList>
            <ArticleId IdType="pubmed">8725305</ArticleId>
          </ArticleIdList>
        </Reference>
        <Reference>
          <Citation>Maekawa K (2004) Prodcuntion and perception of ‘paralinguistic’ Information, Proceedings of International Conference: Speech Prosody 2004, 367–374.</Citation>
        </Reference>
        <Reference>
          <Citation>Boersma P, Weenink D (2011) Praat: Doing phonetics by computer (Version 5.1.04) [Computer Program]. Available: http://www. praat.org/. Accessed 2009 Apr 6.</Citation>
        </Reference>
      </ReferenceList>
    </PubmedData>
  </PubmedArticle>
</PubmedArticleSet>
