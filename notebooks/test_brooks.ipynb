{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feacc17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pingouin import ancova, ttest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32ce3eb",
   "metadata": {},
   "source": [
    "Need to Do for Gender and Race:\n",
    "\n",
    "1. Identify first and last authors\n",
    "2. Identify first and last name separately for each\n",
    "3. Run first name through genderize and output %male to column\n",
    "4. Run last name through ethnicolr and output % of 5 race categories to columns\n",
    "\n",
    "Comparisons & Visualizations\n",
    "1. Histogram of average race estimates for (1) Page 1 Relevance (2) Page 2 Relevance (3) Page 1 Date sort (4) Page 2 Date Sort\n",
    "2. t-test between each race for (1) vs (2) and (1) vs (3)\n",
    "3. Same as 1 & 2 for gender (keeping in mind we only get 1000 genders per IP per day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7da9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/jupyter-brooks.leitner/pubmed-codeathon-team1/data/out/pmid_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c3e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 6)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3511d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_data = data[data['search_type'] == 'relevance']\n",
    "pubdate_desc_data = data[data['search_type'] == 'pubdate_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e51f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb70355",
   "metadata": {},
   "source": [
    "Because RCR works only for papers published earlier than 2021, it will not be possible to compare RCR between relevance and publication date. Will see if average RCR is different between first and second page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0564dc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_data[['page', 'relative_citation_ratio']].plot.hist(alpha=0.5,bins=1000, by='page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64874cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevance_data[['page', 'citation_count']].plot.hist(alpha=0.5,bins=1000, by='page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee579a98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
